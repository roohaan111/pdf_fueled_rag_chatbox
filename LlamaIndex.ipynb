{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LlamaIndex incorporation",
   "id": "82fb25cdafde6da9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T04:26:29.501699Z",
     "start_time": "2025-02-20T04:26:27.770375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.settings import Settings\n",
    "\n",
    "# Set up embedding model using Hugging Face\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Set up LlamaIndex's LLM using Ollama\n",
    "llm = Ollama(model=\"llama3.2\")\n"
   ],
   "id": "2b87bfc2e8a25027",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T04:26:50.163644Z",
     "start_time": "2025-02-20T04:26:46.414865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load PDFs using LlamaIndex's SimpleDirectoryReader\n",
    "pdf_folder = \"/Users/avilochab/Desktop/Job: Work/Chatbox/files\"\n",
    "documents = SimpleDirectoryReader(pdf_folder, required_exts=[\".pdf\"]).load_data()\n",
    "\n",
    "# Configure Settings in LlamaIndex\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm\n",
    "\n",
    "# Create index from documents\n",
    "index = VectorStoreIndex.from_documents(documents)\n"
   ],
   "id": "350478f7bc6d6e4a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 44 0 (offset 0)\n",
      "Ignoring wrong pointing object 46 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 88 0 (offset 0)\n",
      "Ignoring wrong pointing object 90 0 (offset 0)\n",
      "Ignoring wrong pointing object 112 0 (offset 0)\n",
      "Ignoring wrong pointing object 118 0 (offset 0)\n",
      "Ignoring wrong pointing object 120 0 (offset 0)\n",
      "Ignoring wrong pointing object 126 0 (offset 0)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T04:27:41.987506Z",
     "start_time": "2025-02-20T04:27:39.055726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve relevant context\n",
    "query_engine = index.as_query_engine(response_mode=\"no_text\", use_source_nodes=True)\n",
    "query = \"what is the intent behind a scammer\"\n",
    "\n",
    "response = query_engine.query(query)\n",
    "\n",
    "# Extract context from retrieved source nodes\n",
    "extracted_texts = [node.text for node in response.source_nodes]\n",
    "\n",
    "# Format prompt in required style\n",
    "context = \" \".join(extracted_texts)\n",
    "prompt = f\"Based on the following context, answer the question: {query}\\n\\nContext: {context}\\n\\nAnswer:\"\n",
    "\n",
    "# Send formatted prompt to the LLM\n",
    "final_response = llm.complete(prompt)\n",
    "\n",
    "# Print Answer and Citations\n",
    "print(\"\\nAnswer:\\n\", final_response)\n",
    "print(\"\\nCitations:\")\n",
    "for node in response.source_nodes:\n",
    "    print(f\"- {node.metadata.get('file_path', 'Unknown Source')}\")"
   ],
   "id": "99eb5f2b9b5ae7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " The intent behind this scammer is to steal money from the victim's bank account by tricking them into transferring funds to an unauthorized recipient, such as a fake Bank of America representative. The scammer aims to gain control of the victim's account and transfer money out of it.\n",
      "\n",
      "Citations:\n",
      "- /Users/avilochab/Desktop/Job: Work/Chatbox/files/scammer-agent.pdf\n",
      "- /Users/avilochab/Desktop/Job: Work/Chatbox/files/scammer-agent.pdf\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T04:28:16.296406Z",
     "start_time": "2025-02-20T04:28:09.534913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve relevant context\n",
    "query_engine = index.as_query_engine(response_mode=\"no_text\", use_source_nodes=True)\n",
    "query = \"Explain LLM in 100 words\"\n",
    "\n",
    "response = query_engine.query(query)\n",
    "\n",
    "# Extract context from retrieved source nodes\n",
    "extracted_texts = [node.text for node in response.source_nodes]\n",
    "\n",
    "# Format prompt in required style\n",
    "context = \" \".join(extracted_texts)\n",
    "prompt = f\"Based on the following context, answer the question: {query}\\n\\nContext: {context}\\n\\nAnswer:\"\n",
    "\n",
    "# Send formatted prompt to the LLM\n",
    "final_response = llm.complete(prompt)\n",
    "\n",
    "# Print Answer and Citations\n",
    "print(\"\\nAnswer:\\n\", final_response)\n",
    "print(\"\\nCitations:\")\n",
    "for node in response.source_nodes:\n",
    "    print(f\"- {node.metadata.get('file_path', 'Unknown Source')}\")"
   ],
   "id": "fc716809aea53458",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " Here is a 100-word explanation of LLMs (Large Language Models) based on the provided context:\n",
      "\n",
      "A Large Language Model (LLM) is a type of artificial intelligence designed to process and generate human-like language. LLMs use complex algorithms and vast amounts of training data to learn patterns and relationships in language, enabling them to understand and respond to input text. However, their performance can be limited by factors such as overfitting, lack of domain knowledge, and difficulty in processing nuanced hints. To improve LLMs, researchers employ various strategies, including prompt engineering, tailored adaptations, and human-AI collaboration, which can enhance their ability to generate accurate, relevant, and useful responses.\n",
      "\n",
      "Citations:\n",
      "- /Users/avilochab/Desktop/Job: Work/Chatbox/files/LLMs.pdf\n",
      "- /Users/avilochab/Desktop/Job: Work/Chatbox/files/aviationGPT.pdf\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T04:28:42.144656Z",
     "start_time": "2025-02-20T04:28:35.245997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve relevant context\n",
    "query_engine = index.as_query_engine(response_mode=\"no_text\", use_source_nodes=True)\n",
    "query = \"Explain aviationGPT in 100 words\"\n",
    "\n",
    "response = query_engine.query(query)\n",
    "\n",
    "# Extract context from retrieved source nodes\n",
    "extracted_texts = [node.text for node in response.source_nodes]\n",
    "\n",
    "# Format prompt in required style\n",
    "context = \" \".join(extracted_texts)\n",
    "prompt = f\"Based on the following context, answer the question: {query}\\n\\nContext: {context}\\n\\nAnswer:\"\n",
    "\n",
    "# Send formatted prompt to the LLM\n",
    "final_response = llm.complete(prompt)\n",
    "\n",
    "# Print Answer and Citations\n",
    "print(\"\\nAnswer:\\n\", final_response)\n",
    "print(\"\\nCitations:\")\n",
    "for node in response.source_nodes:\n",
    "    print(f\"- {node.metadata.get('file_path', 'Unknown Source')}\")"
   ],
   "id": "38a251e14eb6cdb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " AviationGPT is a large language model designed to provide accurate and contextually relevant responses within the aviation domain. It offers multiple advantages, including versatility in tackling diverse NLP problems, improved performance over rule-based methods (with a 40% gain), reduced model development and maintenance costs, and enhanced utilization of text data. AviationGPT was trained on a large dataset consisting of four sources: aviation-related books, technical reports, product-based work plans, and aviation text databases. The instruction-tuning dataset was created from three sources, including question-answering data, aviation glossaries, and information extraction datasets. With its capabilities, the aviation industry can better address complex issues, enhance efficiency and safety in NAS operations, and discover hidden patterns in maintenance logs.\n",
      "\n",
      "Citations:\n",
      "- /Users/avilochab/Desktop/Job: Work/Chatbox/files/aviationGPT.pdf\n",
      "- /Users/avilochab/Desktop/Job: Work/Chatbox/files/aviationGPT.pdf\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T04:28:59.084204Z",
     "start_time": "2025-02-20T04:28:53.642647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve relevant context\n",
    "query_engine = index.as_query_engine(response_mode=\"no_text\", use_source_nodes=True)\n",
    "query = \"Explain Special forces in 100 words\"\n",
    "\n",
    "response = query_engine.query(query)\n",
    "\n",
    "# Extract context from retrieved source nodes\n",
    "extracted_texts = [node.text for node in response.source_nodes]\n",
    "\n",
    "# Format prompt in required style\n",
    "context = \" \".join(extracted_texts)\n",
    "prompt = f\"Based on the following context, answer the question: {query}\\n\\nContext: {context}\\n\\nAnswer:\"\n",
    "\n",
    "# Send formatted prompt to the LLM\n",
    "final_response = llm.complete(prompt)\n",
    "\n",
    "# Print Answer and Citations\n",
    "print(\"\\nAnswer:\\n\", final_response)\n",
    "print(\"\\nCitations:\")\n",
    "for node in response.source_nodes:\n",
    "    print(f\"- {node.metadata.get('file_path', 'Unknown Source')}\")"
   ],
   "id": "1bf2500c7e221e13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " Here is an explanation of special forces in 100 words:\n",
      "\n",
      "Special operations forces (SOF) are military units trained to conduct unique, high-risk missions in hostile environments. They require specialized skills, equipment, and training to operate effectively. SOF units often conduct clandestine, low-visibility operations, working with indigenous forces and requiring regional expertise. They are characterized by time-sensitive, sensitive, or clandestine nature, and may involve a high degree of risk. The US Special Operations Command (USSOCOM) is the primary organization responsible for training, doctrine, and equipping SOF units, which include components such as Army Rangers, Navy SEALs, Air Force Special Operators, and Marine Forces Special Operations Command.\n",
      "\n",
      "Citations:\n",
      "- /Users/avilochab/Desktop/Job: Work/Chatbox/files/SOF.pdf\n",
      "- /Users/avilochab/Desktop/Job: Work/Chatbox/files/SOF.pdf\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f9e67f6a486982ca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
